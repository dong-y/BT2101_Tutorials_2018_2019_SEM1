{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BT2101 Machine Learning Basic With Tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This notebook should run in Python 3.5+ version."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Goal\n",
    "\n",
    "In this notebook, we will explore deep learning and Tensorflow. <br/>\n",
    "\n",
    "First of all, students should understand machine learning basic knowledge. And then, students can expect to practice machine learning and deep learning models in Tensorflow. More information can be found at https://www.tensorflow.org/install/ and https://keras.io/.\n",
    "\n",
    "Make sure you have already installed tensorflow in your computing, and then you are able to install Keras. **Note that Tensorflow only supports Python 3.5+ version.** If you installed Python 2.7 version in your computer, you could:\n",
    "* Create a new virtual environment with Python 3.5+ in Anaconda \n",
    "* Activate this virtual environment\n",
    "* Install Tensorflow in this virtual environment\n",
    "* Open Python in this virtual environment and type `import tensorflow as tf`\n",
    "* Installation of Tensorflow succeeds if there is not error message returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding:utf-8 -*-\n",
    "# Check whether tensorflow is installed\n",
    "import tensorflow as tf\n",
    "hello = tf.constant('Hello, TensorFlow!')\n",
    "sess = tf.Session()\n",
    "print(sess.run(hello))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Machine Learning Types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic machine learning methods include:\n",
    "\n",
    "1. Supervised Learning\n",
    "\n",
    "The algorithm consists of a target/outcome variable (or dependent variable) which is to be predicted from a given set of predictors (independent variables). Examples include regression, decision tree and KNN.\n",
    "\n",
    "2. Unsupervised Learning\n",
    "\n",
    "The algorithm does not have any target or outcome variable to predict/estimate. It is used for clustering population in different groups, which is widely used for segmenting customers in different groups for specific intervention. Examples include K-means clustering.\n",
    "\n",
    "3. Reinforcement Learning\n",
    "\n",
    "The algorithm trains a machine to make specific decisions. A machine is exposed to an environment where it trains itself continually using trial and error. Examples include Markov Chain Process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Installing Tensorflow and Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get started, install the Tensorflow (CPU version by default or GPU version) in your PC. You need to follow the guide here: https://www.tensorflow.org/install/.\n",
    "* Windows: https://www.tensorflow.org/install/install_windows\n",
    "* Linux: https://www.tensorflow.org/install/install_linux\n",
    "* Mac OS: https://www.tensorflow.org/install/install_mac"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, you need to install Keras. Keras is a high-level neural networks API, written in Python and capable of running on top of TensorFlow, CNTK, or Theano. It was developed with a focus on enabling fast experimentation. You need to follow the guide here: https://keras.io/#installation. After installation, let us try a simple model using Keras."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting started: 30 seconds to Keras\n",
    "Source: https://keras.io/#getting-started-30-seconds-to-keras <br/>\n",
    "Note: This section is the same as the content in the above link. It simply shows how to setup and train a neural network model. \n",
    "\n",
    "The core data structure of Keras is a model, a way to organize layers. The simplest type of model is the `Sequential` model, a linear stack of layers. For more complex architectures, you should use the Keras functional API, which allows to build arbitrary graphs of layers.\n",
    "\n",
    "Here is the `Sequential` model:\n",
    "\n",
    "```python\n",
    "from keras.models import Sequential\n",
    "model = Sequential()\n",
    "```\n",
    "\n",
    "Stacking layers is as easy as `.add()`:\n",
    "\n",
    "```python\n",
    "from keras.layers import Dense\n",
    "model.add(Dense(units=64, activation='relu', input_dim=100))\n",
    "model.add(Dense(units=10, activation='softmax'))\n",
    "```\n",
    "\n",
    "Once your model looks good, configure its learning process with `.compile()`:\n",
    "\n",
    "```python\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='sgd',\n",
    "              metrics=['accuracy'])\n",
    "```\n",
    "\n",
    "If you need to, you can further configure your optimizer. A core principle of Keras is to make things reasonably simple, while allowing the user to be fully in control when they need to (the ultimate control being the easy extensibility of the source code).\n",
    "\n",
    "```python\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.SGD(lr=0.01, momentum=0.9, nesterov=True))\n",
    "```\n",
    "\n",
    "You can now iterate on your training data in batches:\n",
    "\n",
    "```python\n",
    "# x_train and y_train are Numpy arrays --just like in the Scikit-Learn API.\n",
    "model.fit(x_train, y_train, epochs=5, batch_size=32)\n",
    "```\n",
    "\n",
    "Alternatively, you can feed batches to your model manually:\n",
    "\n",
    "```python\n",
    "model.train_on_batch(x_batch, y_batch)\n",
    "```\n",
    "\n",
    "Evaluate your performance in one line:\n",
    "\n",
    "```python\n",
    "loss_and_metrics = model.evaluate(x_test, y_test, batch_size=128)\n",
    "```\n",
    "\n",
    "Or generate predictions on new data:\n",
    "\n",
    "```python\n",
    "classes = model.predict(x_test, batch_size=128)\n",
    "```\n",
    "\n",
    "Building a question answering system, an image classification model, a Neural Turing Machine, or any other model is just as fast. The ideas behind deep learning are simple, so why should their implementation be painful?\n",
    "\n",
    "For a more in-depth tutorial about Keras, you can check out:\n",
    "\n",
    "* [Getting started with the Sequential model](https://keras.io/getting-started/sequential-model-guide)\n",
    "* [Getting started with the functional API](https://keras.io/getting-started/functional-api-guide)\n",
    "\n",
    "In the [examples folder](https://github.com/keras-team/keras/tree/master/examples) of the repository, you will find more advanced models: question-answering with memory networks, text generation with stacked LSTMs, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Experiment Using Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case: Multi-class Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to practice with handwritten digital from MINIST dataset, which is the representative data to explore machine learning techniques. We are going to practice to learn the basics of Keras by walking through a simple example: MINIST consists of $28\\times28$ grayscale images of handwritten digits like these:\n",
    "\n",
    "<img src=\"https://cdn-images-1.medium.com/max/1600/1*_4Ua9Zp84He8OxlZ4cy0DQ@2x.png\" width=\"500\">\n",
    "\n",
    "The dataset also includes labels for each image, telling us which digit it is. For example, the labels for the above images are 5, 0, 4, and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load packages\n",
    "import numpy as np\n",
    "import scipy\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from __future__ import division\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the MNIST data\n",
    "from keras.datasets import mnist\n",
    "\n",
    "# the data, split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ths X data is a 3D Array (images, width, height) of grayscale values. To prepare the data for training, we should convert the 3D Array to matrices by reshaping width and height into a single dimension (i.e., $28\\times28$ images are flatterned into length 784 vectors). Then, we rescale the grayscale values from integers ranging between 0 to 255 into floating point values ranging between 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_new = x_train.reshape(x_train.shape[0], 784) / 255\n",
    "x_test_new = x_test.reshape(x_test.shape[0], 784) / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The y data is an integer vector with values ranging from 0 to 9. To prepare this data for training we should encode the vectors into binary class matrices using the Keras function `to_categorical()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_new = keras.utils.to_categorical(y_train, 10)\n",
    "y_test_new = keras.utils.to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then we can try the sequential model\n",
    "model = Sequential()\n",
    "model.add(Dense(units=256, activation='relu', input_dim=784))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(units=128, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(units=10, activation='softmax'))\n",
    "\n",
    "# The argument for the first layer specifies the shape of the input data (a length 784 numeric vector representing a grayscale image). \n",
    "# The final layer outputs a length 10 numeric vector (probabilities for each digit) using a softmax activation function.\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Some activation functions:\n",
    "\n",
    "<img src=\"https://cdn-images-1.medium.com/max/1600/1*p_hyqAtyI8pbt2kEl6siOQ.png\" width=\"900\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then we can compile the model with appropriate loss function, optimizer and metrics \n",
    "model.compile(loss='categorical_crossentropy', optimizer=keras.optimizers.rmsprop(), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model with 30 epochs and batches of 128 images\n",
    "history = model.fit(x_train_new, y_train_new, epochs=30, batch_size=128, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model performance on test data\n",
    "loss_and_metrics = model.evaluate(x_test_new, y_test_new, batch_size=128)\n",
    "loss_and_metrics #[loss, accuracy]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on test data\n",
    "classes = model.predict(x_test_new, batch_size=128)\n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot loss and accuracy \n",
    "fig = plt.figure()\n",
    "\n",
    "#plt.subplot(1, 2, 1)\n",
    "plt.plot(history.epoch, history.history['val_loss'], 'g-', label='Validation data')\n",
    "plt.plot(history.epoch, history.history['loss'], 'r--', label='Training data')\n",
    "plt.grid(True)\n",
    "plt.xlabel('Number of epochs')\n",
    "plt.ylabel('Loss on training/validation data')\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "plt.show()\n",
    "\n",
    "#plt.subplot(1, 2, 2)\n",
    "plt.plot(history.epoch, history.history['val_acc'], 'g-', label='Validation data')\n",
    "plt.plot(history.epoch, history.history['acc'], 'r--', label='Training data')\n",
    "plt.grid(True)\n",
    "plt.xlabel('Number of epochs')\n",
    "plt.ylabel('Accuracy on training/validation data')\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case: Regression "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to practice with regression problem. In regression, usually output is continuous and numerical, which is different from classification problem.\n",
    "\n",
    "The example here is based on the case in [\"Machine Learning with Python Cookbook\"](#3-References). The codes here are revised and different from the original ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages and load dataset\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X, y = make_regression(n_samples=10000, n_features=3, n_informative=3, n_targets=1, noise=0.0, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup neural network\n",
    "model = Sequential()\n",
    "model.add(Dense(units=32, activation='relu', input_dim=X_train.shape[1]))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(units=32, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(units=1))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complile the model: based on mean-squared-error metrics\n",
    "model.compile(loss='mse', optimizer=keras.optimizers.rmsprop(), metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and fit the neural network\n",
    "history = model.fit(X_train, y_train, epochs=10, batch_size=100, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model performance on test data\n",
    "loss_and_metrics = model.evaluate(X_test, y_test, batch_size=100)\n",
    "loss_and_metrics #mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on test data\n",
    "predict_output = model.predict(X_test, batch_size=100)\n",
    "predict_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot loss and accuracy \n",
    "fig = plt.figure()\n",
    "\n",
    "#plt.subplot(1, 2, 1)\n",
    "plt.plot(history.epoch, history.history['val_loss'], 'g-', label='Validation data')\n",
    "plt.plot(history.epoch, history.history['loss'], 'r--', label='Training data')\n",
    "plt.grid(True)\n",
    "plt.xlabel('Number of epochs')\n",
    "plt.ylabel('Loss on training/validation data')\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "plt.show()\n",
    "\n",
    "#plt.subplot(1, 2, 2)\n",
    "plt.plot(history.epoch, history.history['val_mean_squared_error'], 'g-', label='Validation data')\n",
    "plt.plot(history.epoch, history.history['mean_squared_error'], 'r--', label='Training data')\n",
    "plt.grid(True)\n",
    "plt.xlabel('Number of epochs')\n",
    "plt.ylabel('MSE on training/validation data')\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it is your turn. Read Tensorflow and Keras documents and examples. Familiarize yourself with applications of neural network models. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 References\n",
    "[1] Chris Albon. (2018). Machine Learning with Python Cookbook. O'Reilly."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
